PTQ

现代量化策略：为高效部署而生

量化不仅可以用于训练，更广泛的应用是在模型训练完成后，为了部署和推理进行压缩。这个过程被称为"训练后量化"（Post-Training Quantization, PTQ）。以下是几种前沿的 PTQ 策略。

AWQ (Activation-aware Weight Quantization)

AWQ 是一种智能的量化方法。它认为并非所有权重都同等重要。通过分析模型的"激活值"，AWQ 能识别出对模型性能至关重要的那一小部分权重（约 1%），并在量化过程中对它们进行特殊保护，不降低其精度。而其他 99% 的权重则被压缩到低位宽（如 4-bit）。这种方法通用性强，且能在推理时带来显著的（超过 3 倍）加速。

AffineQuant

这是一种追求极致准确性的高级量化技术。传统量化方法通常只做简单的缩放，而 AffineQuant 则通过引入一个可学习的"仿射变换矩阵"，在量化前对权重和激活值的分布进行优化，使其更"适合"被量化。这能最大程度地减少量化过程中引入的误差，从而在基准测试中取得了顶尖的性能表现。

Unsloth 的动态 4-bit 量化

Unsloth 是一个流行的 LLM 训练优化库，它也提供了一套强大的动态量化方案。与静态量化不同，它能在运行时根据情况灵活调整精度，实现了高压缩率和高精度的完美平衡。例如，它可以将一个模型从 20GB 压缩到 6.5GB，同时保持极高的准确率。

